{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c171448",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision.io.image import ImageReadMode\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import tqdm\n",
    "from typing import Callable\n",
    "import json\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c615ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpscalerDataset(Dataset):\n",
    "    def __init__(self, data:list[tuple[torch.Tensor, torch.Tensor]]):\n",
    "        self.data:list[tuple[torch.Tensor, torch.Tensor]] = data\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> torch.Tensor:\n",
    "        return self.data[idx]\n",
    "\n",
    "def load_dataset() -> list[tuple[torch.Tensor]]:\n",
    "    input_images_dir:str = os.path.join(os.getcwd(), \"Dataset\", \"64x64\")\n",
    "    output_images_dir:str = os.path.join(os.getcwd(), \"Dataset\", \"512x512\")\n",
    "    input_images_path:list[str] = os.listdir(input_images_dir)\n",
    "    output_images_path:list[str] = os.listdir(output_images_dir)\n",
    "    assert len(input_images_path) == len(output_images_path)\n",
    "    dataset: list[tuple[torch.Tensor]] =  list[tuple[torch.Tensor]]()\n",
    "\n",
    "    for image_local_path in input_images_path:\n",
    "        input_image_absolute_path:str = os.path.join(input_images_dir, image_local_path)\n",
    "        output_image_absolute_path:str = os.path.join(output_images_dir, image_local_path)\n",
    "        input_image:torch.Tensor = torchvision.io.read_image(input_image_absolute_path, ImageReadMode.RGB).type(torch.float32) / 255.0\n",
    "        input_image = input_image * 2.0 - 1.0 # Extend the image for the [-1, 1] range\n",
    "        output_image:torch.Tensor = torchvision.io.read_image(output_image_absolute_path, ImageReadMode.RGB).type(torch.float32) / 255.0\n",
    "        output_image = output_image * 2.0 - 1.0 # Extend the image for the [-1, 1] range\n",
    "        dataset.append((input_image.cpu(), output_image.cpu()))\n",
    "    return UpscalerDataset(dataset)\n",
    "\n",
    "dataset:UpscalerDataset = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_image(nb_image:int) -> None:\n",
    "    for _ in range(0, nb_image):\n",
    "        index:int = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "        input_image:torch.Tensor = dataset[index][0] * 0.5 + 0.5\n",
    "        output_image:torch.Tensor = dataset[index][1] * 0.5 + 0.5\n",
    "        input_image = input_image.permute(1, 2, 0)\n",
    "        plt.imshow(input_image)\n",
    "        plt.show()\n",
    "        output_image = output_image.permute(1, 2, 0)\n",
    "        plt.imshow(output_image)\n",
    "        plt.show()\n",
    "        \n",
    "# plot_dataset_image(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpscalerSettings:\n",
    "    def __init__(self, in_channels:int=3, out_channels:int=3, base_channels:int=64, num_rdb_blocks:int=16, rdb_growth_rate:int=32, rdb_num_layers:int=8) -> None:\n",
    "        self.in_channels:int = in_channels\n",
    "        self.out_channels:int = out_channels\n",
    "        self.base_channels:int = base_channels\n",
    "        self.num_rdb_blocks:int = num_rdb_blocks\n",
    "        self.rdb_growth_rate:int = rdb_growth_rate\n",
    "        self.rdb_num_layers:int = rdb_num_layers\n",
    "\n",
    "in_channels:int = 3\n",
    "out_channels:int = 3\n",
    "base_channels:int=64\n",
    "num_rdb_blocks:int=16\n",
    "rdb_growth_rate:int=32\n",
    "rdb_num_layers:int=8\n",
    "model_settings:UpscalerSettings = UpscalerSettings(in_channels, out_channels, base_channels, num_rdb_blocks, rdb_growth_rate, rdb_num_layers)\n",
    "\n",
    "#training params\n",
    "batch_size:int = 5\n",
    "epochs:int = 50\n",
    "test_proportion:float = 0.1\n",
    "\n",
    "base_lr:float = 2e-4\n",
    "def lr_scheduler_fn(step:int) -> float:\n",
    "    return base_lr\n",
    "\n",
    "lr_scheduler:Callable[[int], float] = lr_scheduler_fn\n",
    "\n",
    "saving_epoch_interval:int = 1\n",
    "print_epoch_interval:int = 1\n",
    "nb_sample_to_print:int = 1\n",
    "device:str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, channels:int, growth_rate:int=32, num_layers:int=5):\n",
    "        super().__init__()\n",
    "        self.layers:nn.ModuleList = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            in_channels = channels + i * growth_rate\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels, growth_rate, 3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        \n",
    "        self.lff = nn.Conv2d(channels + num_layers * growth_rate, channels, 1)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        features:list[torch.Tensor] = [x]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            out:torch.Tensor = layer(torch.cat(features, dim=1))\n",
    "            features.append(out)\n",
    "        \n",
    "        return x + self.lff(torch.cat(features, dim=1))\n",
    "\n",
    "class UpscaleBlock(nn.Module):\n",
    "    def __init__(self, channels:int, scale_factor:int=2):\n",
    "        super().__init__()\n",
    "        self.conv:nn.Conv2d = nn.Conv2d(channels, channels * (scale_factor ** 2), 3, padding=1)\n",
    "        self.ps:nn.PixelShuffle = nn.PixelShuffle(scale_factor)\n",
    "        self.relu:nn.ReLU = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.ps(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class RDN_Upscaler(nn.Module):\n",
    "    def __init__(self, in_channels:int=3, out_channels:int=3, base_channels:int=64, num_rdb_blocks:int=16, rdb_growth_rate:int=32, rdb_num_layers:int=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sfe1:nn.Conv2d = nn.Conv2d(in_channels, base_channels, 3, padding=1)\n",
    "        self.sfe2:nn.Conv2d = nn.Conv2d(base_channels, base_channels, 3, padding=1)\n",
    "        \n",
    "        self.rdbs:nn.ModuleList = nn.ModuleList([\n",
    "            ResidualDenseBlock(base_channels, rdb_growth_rate, rdb_num_layers)\n",
    "            for _ in range(0, num_rdb_blocks)\n",
    "        ])\n",
    "        \n",
    "        self.gff:nn.Sequential = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * num_rdb_blocks, base_channels, 1),\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.upscale:nn.Sequential = nn.Sequential(\n",
    "            UpscaleBlock(base_channels, 2),  # 64 -> 128\n",
    "            UpscaleBlock(base_channels, 2),  # 128 -> 256\n",
    "            UpscaleBlock(base_channels, 2),  # 256 -> 512\n",
    "        )\n",
    "        \n",
    "        self.reconstruction:nn.Sequential = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_channels, out_channels, 3, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        sfe1:torch.Tensor = self.sfe1(x)\n",
    "        sfe2:torch.Tensor = self.sfe2(sfe1)\n",
    "        \n",
    "        features:list[torch.Tensor] = [sfe2]\n",
    "        for rdb in self.rdbs:\n",
    "            features.append(rdb(features[-1]))\n",
    "        \n",
    "        global_feat:torch.Tensor = self.gff(torch.cat(features[1:], dim=1))\n",
    "        global_feat = global_feat + sfe1\n",
    "        \n",
    "        upscaled:torch.Tensor = self.upscale(global_feat)\n",
    "        upscaled = self.reconstruction(upscaled)\n",
    "        return torch.tanh(upscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_upscaler(file:str) -> RDN_Upscaler:\n",
    "    model:RDN_Upscaler = RDN_Upscaler(model_settings.in_channels, model_settings.out_channels, model_settings.base_channels, model_settings.num_rdb_blocks, model_settings.rdb_growth_rate, model_settings.rdb_num_layers)\n",
    "    model_path:str = os.path.join(os.getcwd(), \"Models\", file)\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# upscaler:RDN_Upscaler = load_upscaler(\"denoiser.model\")\n",
    "\n",
    "# param_size = 0\n",
    "# for param in upscaler.parameters():\n",
    "#     param_size += param.nelement() * param.element_size()\n",
    "\n",
    "# size_all_mb = (param_size + 0) / (1024**2)\n",
    "# print(\"Model size: {:.3f} MB with {} parameters\".format(size_all_mb, sum(p.numel() for p in upscaler.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainResult:\n",
    "    train_losses:list[float]\n",
    "    test_losses:list[float]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_json(json_str:str) -> 'TrainResult':\n",
    "        d = json.loads(json_str)\n",
    "        return TrainResult(**d)\n",
    "\n",
    "    def __init__(self, train_losses:list[float], test_losses:list[float]) -> None:\n",
    "        self.train_losses = train_losses\n",
    "        self.test_losses = test_losses\n",
    "\n",
    "    def to_json(self) -> str:\n",
    "        return json.dumps(self.__dict__, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07982b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:RDN_Upscaler) -> TrainResult:\n",
    "    resume_train(model, 0)\n",
    "    \n",
    "def resume_train(model:RDN_Upscaler, epoch:int) -> TrainResult:\n",
    "\n",
    "    sample_to_print = min(nb_sample_to_print, batch_size)\n",
    "    epoch = max(0, epoch)\n",
    "\n",
    "    train_result:TrainResult = None\n",
    "    if epoch <= 0:\n",
    "        train_result = TrainResult([], [])\n",
    "    else:\n",
    "        train_res_path:str = f\"./Models/train_result_epoch{epoch}.txt\"\n",
    "        file = open(train_res_path, \"r\")\n",
    "        string = file.read()\n",
    "        train_result  = TrainResult.from_json(string)\n",
    "        file.close()\n",
    "\n",
    "    test_size:int = int(test_proportion * len(dataset))\n",
    "    train_size:int = len(dataset) - test_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    optimizer:torch.optim.Adam = torch.optim.AdamW(model.parameters(), lr=lr_scheduler(0), weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_scheduler)\n",
    "    criterion:_Loss = nn.MSELoss()\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Start training Upscaler\")\n",
    "    with tqdm.tqdm(total=epochs * len(train_dataset), desc=\"Training model\") as pbar:\n",
    "        pbar.update(epoch * len(train_dataset))\n",
    "        for epoch in range(epoch, epochs):\n",
    "            train_loader:DataLoader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "            input_batch:torch.Tensor = None\n",
    "            output_batch:torch.Tensor = None\n",
    "\n",
    "            last_pred_output_batch:torch.Tensor = None\n",
    "            last_output_batch:torch.Tensor = None\n",
    "\n",
    "            total_loss:float = 0.0\n",
    "            for input_batch, output_batch in train_loader:\n",
    "                input_batch = input_batch.to(device)\n",
    "                output_batch = output_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                predicted_image:torch.Tensor = model(input_batch)\n",
    "                loss:torch.Tensor = criterion(predicted_image, output_batch)\n",
    "                total_loss += loss.cpu().item()\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                last_pred_output_batch = predicted_image\n",
    "                last_output_batch = output_batch\n",
    "                pbar.update(input_batch.shape[0])\n",
    "\n",
    "            print_sample:bool = print_epoch_interval > 0 and ((epoch + 1) % print_epoch_interval == 0 or epoch + 1 == epochs)\n",
    "            if print_sample:\n",
    "                for i in range(0, sample_to_print):\n",
    "                    pred_img:torch.Tensor = last_pred_output_batch[i].detach().cpu() * 0.5 + 0.5\n",
    "                    output_img:torch.Tensor = last_output_batch[i].detach().cpu() * 0.5 + 0.5\n",
    "                    print(\"target image :\")\n",
    "                    plt.imshow(output_img.permute(1, 2, 0))\n",
    "                    plt.show()\n",
    "                    print(\"Predict image :\")\n",
    "                    plt.imshow(pred_img.permute(1, 2, 0))\n",
    "                    plt.show()\n",
    "\n",
    "            train_loss:float = total_loss / (len(train_dataset) / batch_size)\n",
    "            train_result.train_losses.append(train_loss)\n",
    "\n",
    "            total_loss = 0.0\n",
    "            test_loader:DataLoader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "            with torch.no_grad():\n",
    "                for input_batch, output_batch in test_loader:\n",
    "                    input_batch = input_batch.to(device)\n",
    "                    output_batch = output_batch.to(device)\n",
    "                    predicted_image:torch.Tensor = model(input_batch)\n",
    "                    loss:torch.Tensor = criterion(predicted_image, output_batch)\n",
    "                    total_loss += loss.cpu().item()\n",
    "                train_result.test_losses.append(total_loss / (len(test_dataset) / batch_size))\n",
    "\n",
    "            save_epoch:bool = saving_epoch_interval >= 1 and ((epoch + 1) % saving_epoch_interval == 0 or epoch + 1 == epochs)\n",
    "            if save_epoch:\n",
    "                path:str = f\"./Models/upscaler_epoch{epoch}.model\" if epoch < epochs - 1 else \"./Models/upscaler.model\"\n",
    "                if os.path.isfile(path):\n",
    "                    os.remove(path)\n",
    "                torch.save(model.state_dict(), path)\n",
    "\n",
    "                train_res_path:str = f\"./Models/train_result_epoch{epoch}.txt\" if epoch < epochs - 1 else \"./Models/train_result.txt\"\n",
    "                file = open(train_res_path, \"w\")\n",
    "                file.write(train_result.to_json())\n",
    "                file.close()\n",
    "\n",
    "        return train_result\n",
    "    \n",
    "upscaler:RDN_Upscaler = RDN_Upscaler(model_settings.in_channels, model_settings.out_channels, model_settings.base_channels, model_settings.num_rdb_blocks, model_settings.rdb_growth_rate, model_settings.rdb_num_layers)\n",
    "seed:int = 2442157549\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "train_result:TrainResult = train(upscaler)\n",
    "\n",
    "# epoch_to_resume:int = 549\n",
    "# upscaler:RDN_Upscaler = load_upscaler(f\"upscaler_epoch{epoch_to_resume}.model\")\n",
    "# train_result:TrainResult = resume_train(upscaler, epoch_to_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_training_result(train_result:TrainResult) -> None:\n",
    "    assert len(train_result.test_losses) == len(train_result.test_losses)\n",
    "    X:list[float] = [float(i) for i in range(1, len(train_result.test_losses) + 1)]\n",
    "    plt.plot(X, train_result.train_losses, label='train loss')\n",
    "    plt.plot(X, train_result.test_losses, label='test loss')\n",
    "    plt.title(\"Losses\", fontsize=18)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "train_res_path:str = f\"./Models/train_result_epoch{549}.txt\"\n",
    "file = open(train_res_path, \"r\")\n",
    "train_result:TrainResult = TrainResult.from_json(file.read())\n",
    "file.close()\n",
    "show_training_result(train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35121c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(upscaler:RDN_Upscaler, test_size:int) -> None:\n",
    "    upscaler.to(device)\n",
    "    with torch.no_grad():\n",
    "        test_data:list[tuple[torch.Tensor]] = [dataset[random.randint(0, len(dataset) - 1)] for _ in range(0, test_size)]\n",
    "        input_batch:torch.Tensor = torch.stack([image[0] for image in test_data]).to(device)\n",
    "        output_batch:torch.Tensor = torch.stack([image[1] for image in test_data]).to(device)\n",
    "        pred_images:torch.Tensor = upscaler(input_batch)\n",
    "\n",
    "        for i in range(0, test_size):\n",
    "            print(\"Output image : \")\n",
    "            plt.imshow((output_batch[i].cpu() * 0.5 + 0.5).permute(1, 2, 0))\n",
    "            plt.show()\n",
    "\n",
    "            print(\"Predicted image : \")\n",
    "            plt.imshow((pred_images[i].cpu() * 0.5 + 0.5).permute(1, 2, 0))\n",
    "            plt.show()\n",
    "\n",
    "upscaler:RDN_Upscaler = load_upscaler(f\"upscaler_epoch{549}.model\")\n",
    "test_model(upscaler, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
